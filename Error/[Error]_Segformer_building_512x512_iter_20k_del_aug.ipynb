{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27095,"status":"ok","timestamp":1652409249792,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"nllMQ6RCsenv","outputId":"f90c88c3-08a6-4401-ca34-070ed12ddcb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10771,"status":"ok","timestamp":1652409260559,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"PPb5e_glt9i6","outputId":"2c794267-bcc3-4655-acbf-49860070bff9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n","Collecting mmcv-full\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (46.3 MB)\n","\u001b[K     |████████████████████████████████| 46.3 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.8)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.5.0 yapf-0.32.0\n","Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 6994, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 6994 (delta 1), reused 0 (delta 0), pack-reused 6988\u001b[K\n","Receiving objects: 100% (6994/6994), 12.82 MiB | 9.01 MiB/s, done.\n","Resolving deltas: 100% (5183/5183), done.\n"]}],"source":["!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n","!git clone https://github.com/open-mmlab/mmsegmentation.git"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2700,"status":"ok","timestamp":1652409263254,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"zU2hdo-iuDM_","outputId":"8d370e86-d76c-4371-ac48-05a79f0b1aea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.11.0+cu113 (Tesla T4)\n"]}],"source":["import torch\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652409263254,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"5Y38Lq6KuG75","outputId":"a0013d80-5373-461c-9e72-4c999714072b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmsegmentation\n"]}],"source":["%cd mmsegmentation"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"scnWNR9VuKnB","executionInfo":{"status":"ok","timestamp":1652409265012,"user_tz":-540,"elapsed":1761,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n","import mmcv"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nZ7kLaEfuMhh","executionInfo":{"status":"ok","timestamp":1652409265013,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["import os.path as osp\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32576,"status":"ok","timestamp":1652409297584,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"O5uVMzGxuRlJ","outputId":"a87910bc-8c36-47c7-faaf-2569c490b361"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-13 02:34:26--  https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.18\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.18|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 328290585 (313M) [application/octet-stream]\n","Saving to: ‘//content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth’\n","\n","//content/mmsegment 100%[===================>] 313.08M  9.74MB/s    in 31s     \n","\n","2022-05-13 02:34:58 (9.95 MB/s) - ‘//content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth’ saved [328290585/328290585]\n","\n"]}],"source":["!mkdir checkpoints\n","!wget -O //content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"km0JLIuRumCX","executionInfo":{"status":"ok","timestamp":1652409297585,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["from mmseg.datasets.builder import DATASETS\n","from mmseg.datasets.custom import CustomDataset\n","\n","classes = ('background', 'building')\n","palette = [[0, 0, 0], [128, 128, 0]]\n","\n","@DATASETS.register_module()\n","class SIADataset(CustomDataset):\n","  CLASSES = classes\n","  PALETTE = palette\n","  def __init__(self, split, **kwargs):\n","    super().__init__(img_suffix='.png', seg_map_suffix='.png', \n","                     split=split, **kwargs)\n","    assert osp.exists(self.img_dir) and self.split is not None"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652409297585,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"Qx5ugOgwuxGW","outputId":"51de8239-f030-4847-ccfa-8be8093ea67b"},"outputs":[{"output_type":"stream","name":"stdout","text":["norm_cfg = dict(type='SyncBN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=None,\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1,\n","        init_cfg=dict(type='Pretrained', checkpoint='pretrain/mit_b5.pth')),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=19,\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='slide', crop_size=(1024, 1024), stride=(768, 768)))\n","dataset_type = 'CityscapesDataset'\n","data_root = 'data/cityscapes/'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (1024, 1024)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(2048, 1024),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=1,\n","    train=dict(\n","        type='CityscapesDataset',\n","        data_root='data/cityscapes/',\n","        img_dir='leftImg8bit/train',\n","        ann_dir='gtFine/train',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(\n","                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n","            dict(\n","                type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n","            dict(type='RandomFlip', prob=0.5),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ]),\n","    val=dict(\n","        type='CityscapesDataset',\n","        data_root='data/cityscapes/',\n","        img_dir='leftImg8bit/val',\n","        ann_dir='gtFine/val',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict(\n","        type='CityscapesDataset',\n","        data_root='data/cityscapes/',\n","        img_dir='leftImg8bit/val',\n","        ann_dir='gtFine/val',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]))\n","log_config = dict(\n","    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(\n","    type='AdamW',\n","    lr=6e-05,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys=dict(\n","            pos_block=dict(decay_mult=0.0),\n","            norm=dict(decay_mult=0.0),\n","            head=dict(lr_mult=10.0))))\n","optimizer_config = dict()\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-06,\n","    power=1.0,\n","    min_lr=0.0,\n","    by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=160000)\n","checkpoint_config = dict(by_epoch=False, interval=16000)\n","evaluation = dict(interval=16000, metric='mIoU', pre_eval=True)\n","\n"]}],"source":["# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정. \n","config_file = '/content/mmsegmentation/configs/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes.py'\n","checkpoint_file = '/content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n","from mmcv import Config\n","\n","cfg = Config.fromfile(config_file)\n","print(cfg.pretty_text)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"caVFRT7QvWE8","executionInfo":{"status":"ok","timestamp":1652409297585,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["cfg.norm_cfg = dict(type='BN', requires_grad=True)\n","#cfg.model.backbone.norm_cfg = cfg.norm_cfg\n","cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n","\n","cfg.model.decode_head.num_classes = 2"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"X9IpatmxvYMt","executionInfo":{"status":"ok","timestamp":1652409297585,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["cfg.img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","#cfg.crop_size = (512, 512)\n","cfg.train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n","    #dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(type='Normalize', **cfg.img_norm_cfg),\n","    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","\n","cfg.val_pipeline = [\n","                    dict(type='LoadImageFromFile'),\n","                    dict(\n","                        type='MultiScaleFlipAug',\n","                        img_scale=(1024, 1024),\n","                        flip=False,\n","                        transforms=[\n","                                    dict(type='Resize', keep_ratio=True),\n","                                    #dict(type='RandomFlip'),\n","                                    dict(\n","                                        type='Normalize',\n","                                        mean=[123.675, 116.28, 103.53],\n","                                        std=[58.395, 57.12, 57.375],\n","                                        to_rgb=True),\n","                                    dict(type='ImageToTensor', keys=['img']),\n","                                    dict(type='Collect', keys=['img'])\n","                                    ]),\n","                    \n","]\n","\n","cfg.test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='ResizeToMultiple', size_divisor=32),\n","            #dict(type='RandomFlip'),\n","            dict(type='Normalize', **cfg.img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_4PNB6hGvds4","executionInfo":{"status":"ok","timestamp":1652409297586,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["cfg.dataset_type = 'SIADataset'\n","cfg.data_root = '/content/drive/MyDrive/SIA'\n","\n","cfg.data.train.type = 'SIADataset'\n","cfg.data.train.data_root = '/content/drive/MyDrive/SIA'\n","cfg.data.train.img_dir = 'images/up025'\n","cfg.data.train.ann_dir = 'labels'\n","cfg.data.train.pipeline = cfg.train_pipeline\n","cfg.data.train.split = '/content/drive/MyDrive/SIA/splits/building/train_building.txt'\n","cfg.data.val.type = 'SIADataset'\n","cfg.data.val.data_root = '/content/drive/MyDrive/SIA'\n","cfg.data.val.img_dir = 'images/up025'\n","cfg.data.val.ann_dir = 'labels'\n","cfg.data.val.pipeline = cfg.test_pipeline\n","cfg.data.val.split = '/content/drive/MyDrive/SIA/splits/building/val_building.txt'\n","\n","cfg.data.test.type = 'SIADataset'\n","cfg.data.test.data_root = '/content/drive/MyDrive/SIA'\n","cfg.data.test.img_dir = 'images/up025'\n","cfg.data.test.ann_dir = 'labels'\n","cfg.data.test.pipeline = cfg.test_pipeline\n","cfg.data.test.split = '/content/drive/MyDrive/SIA/splits/building/val_building.txt'"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"jXNN3BblvrfK","executionInfo":{"status":"ok","timestamp":1652409297586,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["cfg.data.train.type = 'SIADataset'\n","cfg.data.train.data_root = '/content/drive/MyDrive/SIA'\n","cfg.data.train.img_dir = 'images/up025'\n","cfg.data.train.ann_dir = 'labels'\n","cfg.data.train.pipeline = cfg.train_pipeline\n","cfg.data.train.split = '/content/drive/MyDrive/SIA/splits/building/train_building.txt'"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"l1Gc8ttSvw8e","executionInfo":{"status":"ok","timestamp":1652409297586,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["cfg.load_from = '/content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n","\n","# Set up working dir to save files and logs.\n","cfg.work_dir = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building_del_aug'"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":697,"status":"ok","timestamp":1652409298278,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"},"user_tz":-540},"id":"vvSIfRurv0sm","outputId":"4a8263b2-738a-4c34-9ece-68dcd4b535d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config:\n","norm_cfg = dict(type='BN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=None,\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1,\n","        init_cfg=dict(type='Pretrained', checkpoint='pretrain/mit_b5.pth')),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='slide', crop_size=(1024, 1024), stride=(768, 768)))\n","dataset_type = 'SIADataset'\n","data_root = '/content/drive/MyDrive/SIA'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (1024, 1024)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='ResizeToMultiple', size_divisor=32),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=1,\n","    train=dict(\n","        type='SIADataset',\n","        data_root='/content/drive/MyDrive/SIA',\n","        img_dir='images/up025',\n","        ann_dir='labels',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(\n","                type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),\n","            dict(\n","                type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ],\n","        split='/content/drive/MyDrive/SIA/splits/building/train_building.txt'),\n","    val=dict(\n","        type='SIADataset',\n","        data_root='/content/drive/MyDrive/SIA',\n","        img_dir='images/up025',\n","        ann_dir='labels',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='ResizeToMultiple', size_divisor=32),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        split='/content/drive/MyDrive/SIA/splits/building/val_building.txt'),\n","    test=dict(\n","        type='SIADataset',\n","        data_root='/content/drive/MyDrive/SIA',\n","        img_dir='images/up025',\n","        ann_dir='labels',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='ResizeToMultiple', size_divisor=32),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        split='/content/drive/MyDrive/SIA/splits/building/val_building.txt'))\n","log_config = dict(\n","    interval=100, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = '/content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(\n","    type='AdamW',\n","    lr=6e-05,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys=dict(\n","            pos_block=dict(decay_mult=0.0),\n","            norm=dict(decay_mult=0.0),\n","            head=dict(lr_mult=10.0))))\n","optimizer_config = dict()\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-06,\n","    power=1.0,\n","    min_lr=0.0,\n","    by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=20000)\n","checkpoint_config = dict(by_epoch=False, interval=1000)\n","evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)\n","val_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","work_dir = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building_del_aug'\n","seed = 0\n","gpu_ids = range(0, 1)\n","\n"]}],"source":["cfg.runner.max_iteTrs = 200\n","cfg.log_config.interval = 100\n","cfg.evaluation.interval = 1000  # 모델 학습시 평가를 몇 번째 iteration마다 할 것인지 지정\n","cfg.checkpoint_config.interval = 1000  # 모델 학습시 학습한 모델을 몇 번째 iteration마다 저장할 것인지 지정\n","\n","cfg.runner = dict(type='IterBasedRunner', max_iters=20000)  # Iteration으로 동작, Epoch로 동작하게 변경할 수도 있음\n","# cfg.runner = dict(type='EpochBasedRunner', max_epochs=4000)  # Epoch로 변경\n","cfg.workflow = [('train', 1)]\n","\n","# Set seed to facitate reproducing the result\n","cfg.seed = 0\n","#set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","\n","# Let's have a look at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')"]},{"cell_type":"markdown","source":["### 모델 학습"],"metadata":{"id":"xP_db_FP_lnS"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8IlH2WxNwFFW","outputId":"ae39401a-f000-47ff-f3bd-4a302529beeb","executionInfo":{"status":"error","timestamp":1652409327940,"user_tz":-540,"elapsed":29665,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-13 02:35:00,936 - mmseg - INFO - Loaded 600 images\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  'Default ``avg_non_ignore`` is False, if you would like to '\n","2022-05-13 02:35:13,704 - mmseg - INFO - Loaded 147 images\n","2022-05-13 02:35:13,708 - mmseg - INFO - load checkpoint from local path: /content/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth\n","2022-05-13 02:35:14,147 - mmseg - WARNING - The model and loaded state dict do not match exactly\n","\n","size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n","size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([2]).\n","2022-05-13 02:35:14,153 - mmseg - INFO - Start running, host: root@262d723f9207, work_dir: /content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building_del_aug\n","2022-05-13 02:35:14,154 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-05-13 02:35:14,157 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters\n","2022-05-13 02:35:14,158 - mmseg - INFO - Checkpoints will be saved to /content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building_del_aug by HardDiskBackend.\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c07218ae94fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m train_segmentor(model, datasets, cfg, distributed=False, validate=True,\n\u001b[0;32m---> 18\u001b[0;31m                 meta=dict(CLASSES=classes, PALETTE=palette))\n\u001b[0m","\u001b[0;32m/content/mmsegmentation/mmseg/apis/train.py\u001b[0m in \u001b[0;36mtrain_segmentor\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_iters, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0miter_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/mmsegmentation/mmseg/datasets/custom.py\", line 215, in __getitem__\n    return self.prepare_train_img(idx)\n  File \"/content/mmsegmentation/mmseg/datasets/custom.py\", line 232, in prepare_train_img\n    return self.pipeline(results)\n  File \"/content/mmsegmentation/mmseg/datasets/pipelines/compose.py\", line 41, in __call__\n    data = t(data)\n  File \"/content/mmsegmentation/mmseg/datasets/pipelines/formatting.py\", line 281, in __call__\n    img_meta[key] = results[key]\nKeyError: 'flip'\n"]}],"source":["from mmseg.datasets import build_dataset\n","from mmseg.models import build_segmentor\n","from mmseg.apis import train_segmentor\n","\n","# Build the dataset\n","datasets = [build_dataset(cfg.data.train)]\n","\n","# Build the detector\n","model = build_segmentor(\n","    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n","\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES\n","\n","# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","train_segmentor(model, datasets, cfg, distributed=False, validate=True,\n","                meta=dict(CLASSES=classes, PALETTE=palette))"]},{"cell_type":"markdown","source":["### 모델 결과 시각화"],"metadata":{"id":"Pre69QNK_dwU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-CqkRGDw6Im","executionInfo":{"status":"aborted","timestamp":1652409327935,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"outputs":[],"source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building_del_aug/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/OBJ00175_PS3_K3_NIA0081.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_1000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/OBJ00004_PS3_K3_NIA0078.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"bAryRhyH31AP","executionInfo":{"status":"aborted","timestamp":1652409327936,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/OBJ01403_PS3_K3_NIA0093.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"h0mU3zKc37JV","executionInfo":{"status":"aborted","timestamp":1652409327936,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/OBJ02447_PS3_K3_NIA0122.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"UL2xF1Cf3ozJ","executionInfo":{"status":"aborted","timestamp":1652409327936,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/OBJ03325_PS3_K3A_NIA0137.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"JgU4bl_C4DIb","executionInfo":{"status":"aborted","timestamp":1652409327937,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/BLD00768_PS3_K3A_NIA0277.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"74PTFU5O3QsZ","executionInfo":{"status":"aborted","timestamp":1652409327937,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/BLD01556_PS3_K3A_NIA0373.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"Lw0EBy2p3TRP","executionInfo":{"status":"aborted","timestamp":1652409327937,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/BLD11632_PS3_K3A_NIA0390.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"tKGGoyxz3TX2","executionInfo":{"status":"aborted","timestamp":1652409327937,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/images/up025/BLD00223_PS3_K3A_NIA0276.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"wje602xT3TeL","executionInfo":{"status":"aborted","timestamp":1652409327938,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zaMmcExB3TmF","executionInfo":{"status":"aborted","timestamp":1652409327938,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/naver_map_images/0000.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"mRyOn2F12wOz","executionInfo":{"status":"aborted","timestamp":1652409327938,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/naver_map_images/0001.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"tWdANvJq2wOz","executionInfo":{"status":"aborted","timestamp":1652409327939,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_file = '/content/drive/MyDrive/SIA/semantic_checkpoint/Segformer/building/batch2/iter_20000.pth'  #학습된 모델\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu 사용\n","\n","img = mmcv.imread('/content/drive/MyDrive/SIA/naver_map_images/0002.png')\n","result = inference_segmentor(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, palette)"],"metadata":{"id":"_bRpUIRQ2wOz","executionInfo":{"status":"aborted","timestamp":1652409327939,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zRz71RgiUXA6","executionInfo":{"status":"aborted","timestamp":1652409327939,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tanvi Kumar","userId":"07755411692647467598"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"[Error]_Segformer_building_512x512_iter_20k_del_aug.ipynb","provenance":[{"file_id":"1-tUNSqxwGyamS6a3CkRHoXF5GMszfber","timestamp":1652320453219}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}